#! usr/bin/python
#-------------------------------
# elanfmt.py
# @version: 0.8
# @updated: 8/6/2010
#-------------------------------
# @author: Andrew Wood
# @contact: andywood@vt.edu
#
# HLP/Jaeger Lab
# University of Rochester
# Rochester, NY
#-------------------------------

"""Collection of functions to recursively search for and parse ELAN annotation files.

This script takes a directory as its search root, as well as a string of filters to control what is extracted from the ELAN files.
Optionally, elanfmt.py can examine transcripts as it is parsing, to pick up new information, such as @regions.
Output data may be written to a new output file, or merged with an existing CSV file.

elanfmt.py uses ELAN output files generated by the Ting Automatic Speech Aligner. 
"""

import os
import sys
import copy
import csv
from re import sub
from xml.dom import minidom
from lutil import *

COLUMN_SUBJECT = "Participant"
COLUMN_STIMULUS = "Trial"
COLUMN_LATENCY = "Latency"

headers=[COLUMN_SUBJECT, COLUMN_STIMULUS, COLUMN_LATENCY]
VERBOSE=True

def pathSplit(path):
	"""
	Split a path name across the '/' (or '\' in Windows) character
	"""
	if os.name is "nt":
		return path.split("\\")
	else:
		return path.split("/")

def getStimInfo(path):
	"""
	Return a tuple of the path's parent and grandparent directory nodes
	"""
	s = pathSplit(path)
	return (s[-3], s[-2])


# Data Extraction Functions  -------------------------

def filterGen(filterList):
	""" 
	Generate the filter used for determining what timing information to display
	-Arguments: filterList -- list of 'layer:value1,value2,...' pairs
	-Return: filter -- dictionary with a key for each layer and a corresponding list of values
	"""
	
	if VERBOSE: print "Generating filter...",
	
	filter = {}

	#make sure we're dealing with a list of strings, not a nested list
	if type(filterList) is list: filterList = flatten(filterList)
	
	#make sure input string is maximally split and flatten(again) into uniform depth
	filterList = flatten(multisplit(filterList, [" ",",",";"])) 
	currentKey = None
	
	for f in filterList:
		attemptedSplit = f.split(":")
		if len(attemptedSplit)==2:
			currentKey = attemptedSplit[0].upper()
			if attemptedSplit[1] != "": filter[currentKey] = [attemptedSplit[1].lower()]
		else:
			if currentKey is not None and len(attemptedSplit) == 1:
				filter[currentKey].append(f.lower())
			else:
				print "Error: Syntax error in filter string, should be of form 'key:val1,val2,... key2:val1,val2,... ...'"	
	
	buildHeader(filter)
	if VERBOSE: print "done."
	return filter		

def buildHeader(filter):
	for k, v in filter.iteritems():
		for item in v:
			pairstr = k.capitalize()+item.capitalize()
			headers.extend(["Onset"+pairstr,"Duration"+pairstr])

def parseElan(elanFile, subjectID, stimID, filter=None, checkTranscript=False, includeNonWord=False):
	"""
	Parse an ELAN generated annotation file
	-Arguments:
	  * elanFile -- the filename of the ELAN (XML) file to parse
	  * subjectID -- identifying info for the current participant
	  * stimID -- identifier for the current stimulus; together with subjectID identifies a row of output
	  * filter -- filter to apply to determine what info to extract. 
	     Default=None : return only latency information
	  * checkTranscript -- if true, consult an external transcript file to supply new information
	     Default=False
	  * includeNonWord -- if true, include non word sounds as words (for purposes of indexing)
	-Return
	  * data -- dictionary containing an entry for each of the desired fields given by filter.  
	"""
	
	#Parse the XML ELAN file and gather the pertinent parts
	doc = minidom.parse(elanFile)
	times = doc.getElementsByTagName("TIME_SLOT")
	tiers = doc.getElementsByTagName("TIER")
	
	#write row identifying information
	dataline = filldict(headers, "-") #(make sure all datalines have same fields
	dataline.update({COLUMN_SUBJECT: subjectID, \
					COLUMN_STIMULUS: stimID, \
					COLUMN_LATENCY: times[0].attributes["TIME_VALUE"].value,})
	
	#Default behavior, return only latency
	if filter is None: return dataline;
	
	for tier in tiers:
		#if filter contains entries for tier, process them
		key = tier.attributes["TIER_ID"].value.upper()
		if key in filter.keys():
			#check if each annotation entry is in the filter 
			#(saves searching the annotations multiple times)
			nwOffset = 0
			for i, item in enumerate(tier.getElementsByTagName("ALIGNABLE_ANNOTATION")):
				itemdata = item.childNodes[1].firstChild.data.lower()
				
				#Determine if either the word/phoneme/region/index/etc is a match
				if itemdata in filter[key] or str(i+1-nwOffset) in filter[key]:					
					try:
						#extract timing information
						#get time indices 	
						timeindex1 = int(item.attributes["TIME_SLOT_REF1"].value[2:])-1
						timeindex2 = int(item.attributes["TIME_SLOT_REF2"].value[2:])-1
						#use indices to get onset and duration
						onset = times[timeindex1].attributes["TIME_VALUE"].value
						duration = int(times[timeindex2].attributes["TIME_VALUE"].value) - int(onset)
					except ValueError:
						print "WARNING: bad timing info at: \n\tsubject %s,\n\tstimulus %s,\n\ttier %s,\n\titem# %s" %(subjectID, stimID, tier.attributes["TIER_ID"].value, i+1)
						continue
					#Remember that both keyword and index may match at the same time
					#for keyword search
					if itemdata in filter[key]:
						filterpair = key.capitalize()+itemdata.capitalize()
						#write the data fields
						dataline["Onset"+filterpair] = int(onset)
						dataline["Duration"+filterpair] = int(duration)	
					#for index search
					#prevent ++SOUND++ entries from matching if includeNonWord is false									
					if not includeNonWord and itemdata == "++"+itemdata[2:-2]+"++":
						nwOffset += 1
					elif str(i+1-nwOffset) in filter[key]:
						filterpair = key.capitalize()+str(i+1-nwOffset)
						#write the data fields
						dataline["Onset"+filterpair] = int(onset)
						dataline["Duration"+filterpair] = int(duration)	

					
	return dataline				
							
def getData(dir, filter=None, checkTranscript=False):
	"""
	Recursive function to walk the directory structure and locate ELAN files
	-Arguments: 
	  * dir -- directory to recursively search
	  * filter -- filter to apply to parseElan
	  * checkTranscript -- boolean value to pass on to parseElan
	-Return:
	  * data -- recursively generated list of data dictionaries produced by parseElan
	"""
	
	#the dictionary which contains the data
	data = []
	
	#make sure dir is actually a directory
	if os.path.isdir(dir):
			os.chdir(dir)
	else:
		print "ERROR: '"+dir+"' is not a directory."
		sys.exit(1)	
	curPath = os.getcwd()
	
	#examine the contents of dir; if a directory, recurse; otherwise check if an elan file
	for f in os.listdir(curPath):
		newpath = curPath+"/"+f
		if os.path.isdir(newpath):
			data.extend(getData(newpath, filter, checkTranscript))
		else:
			if str(f).endswith(".eaf"):
				s = pathSplit(curPath)[-2:]
				data = [parseElan(f, sub("_[A-Z]*","",s[0]), sub(".wav","",s[1]), filter, checkTranscript)]
	return data			


# Data Processor Functions (format and output) -------------------------------

def indexData(data):
	"""
	Convert the input list into a dictionary format for use in merging with existing data
	-Arguments: data -- list to be converted to dictionary form
	-Return: datadict -- dictified data
	"""
	if VERBOSE: print "Indexing extracted data...",
	datadict = {}
	for datum in data:
		datadict["%s%s" %(datum[COLUMN_SUBJECT],datum[COLUMN_STIMULUS])] = datum
	if VERBOSE: print "done"
	return datadict

def printData(data, outfile):
	"""
	Method to simply create a new output file without merging
	-Arguments:
	  * data -- data dictionary to be printed
	  * outfile -- output destination
	-Return: nothing
	"""
	if VERBOSE: print "Outputting to new file: ",outfile
	with open(outfile, "w") as fout:
		writer = csv.DictWriter(fout, headers, delimiter=",", quotechar='"', quoting=csv.QUOTE_ALL, lineterminator="\n")
		writer.writeheader()
		writer.writerows(data)

def mergeData(data, infile, outfile=None):
	"""
	Merge the data generated from parsing ELAN files with an existing CSV file
	-Arguments:
	 * data -- data dictionary to be added to the existing file
	 * infile -- filename of the existing CSV file
	 * outfile -- filename for the new file.
	  Default: None -- will update the infile in place
	-Return: nothing
	"""
	if VERBOSE: print "Merging with existing file: ",infile
	tmpfile = ".elanfmt-tmp"
	
	with open(infile, "rb") as fin:
		with open(tmpfile, "wb") as fout:
			#initialize the input file reader
			csvin = csv.DictReader(fin, delimiter=",", quotechar='"', quoting=csv.QUOTE_ALL, lineterminator="\n")
			
			#generate the complete field list for output file
			fields = copy.deepcopy(csvin.fieldnames)
			for field in headers: 
				if field not in fields: fields.append(field);
			
			#initialize the output file writer and output file
			csvout = csv.DictWriter(fout, fields, delimiter=",", quotechar='"', quoting=csv.QUOTE_ALL, lineterminator="\n")
			csvout.writerow(dict(zip(fields,fields)))
			
			#for each line in the input file, update with the corresponding line of data
			#then, write to Excel-readable CSV file
			for line in csvin:
				#if there is data for a line, update the line and output.
				try:
					line.update(data[line[COLUMN_SUBJECT]+line[COLUMN_STIMULUS]])
					csvout.writerow(line)
				#if not, copy over the existing data, leaving the new columns blank
				except KeyError:
					datum = filldict(fields, "")
					for key, value in line.iteritems():
						datum[key] = value
					csvout.writerow(datum)
	
	if outfile is not None:
		if VERBOSE: print "Outputting to new file: ",outfile
		if os.path.isfile(outfile):
			os.remove(outfile)
		os.rename(tmpfile, outfile)
	else:
		if VERBOSE: print "Outputting to same file: ",infile
		if os.path.isfile(infile):
			os.remove(infile)
		os.rename(tmpfile, infile)

def outputData(data, infile=None, outfile=None):
	"""
	Simple function to route the data to the appropriate file writing function
	-Arguments:
	 * data -- list of data from ELAN files to be indexed and output
	 * infile -- filename of an existing CSV file to update
	  Default: None - data is written to a new file
	 * outfile -- filename of a target output file (will be overwritten if it already exists)
	  Default: None - infile is updated in place if it exists; if not, output file is 'out.csv'
	 * destpath -- place to put the output file
	  Default: the current working directory ('.')
	"""
	if infile == None:
		if outfile == None:
			outfile = "out.csv"
		printData(data, outfile)
	else:
		index = indexData(data)
		mergeData(index, infile, outfile)
					
# Main Module Function  -------------------------------
def elanfmt(root=".", filterin=None, infile=None, outfile=None, chkTranscript=False):
	"""
	Modular function to completely process ELAN files
	-Arguments:
	 * root -- directory to search from (for getData)
	 * filterin -- filter descriptor, can be as a string, or an arbitrarily nested list of strings, provided they follow the syntax rules if flattened and joined
	 * infile -- CSV file to add data to, leave blank to create new output file
	 * outfile -- desired output filename. Leave blank to create 'out.csv' if creating a new file, or to update infile in place
	 * chkTranscript -- flag to consult transcript files for updated region information.
	-Return:
	 * Nothing. Merges results with infile, or creates a new CSV data file
	"""
	#Generate the filter
	if filterin is not None: filter = filterGen(filterin)
	else: filter = None
	
	#Collect Data
	if VERBOSE: print "Getting data..."
	startingpath = os.getcwd() #remember the starting path, to preserve local directory references
	data = getData(root, filter, chkTranscript)
	os.chdir(startingpath)
	if VERBOSE: print "done"
		
	#Output Data
	outputData(data, infile, outfile)


# Script Functions ---------------------------------

def main():
	"""
	Main method, contains the UI (command line arg processing). Run with parameter '-help' for usage.
	"""
	
	helpstring = \
		"-----------------\n"+\
		"elanfmt.py\n"+\
		"-----------------\n"+\
		"USAGE: python elanfmt.py [PARAMETERS] [--input|-i INPUT_FILENAME] [--output|-o OUTPUT_FILENAME] DIRECTORY [FILTER_STRING]\n\n"+\
		"Command Line Options and Parameters:\n"+\
		"  --help : print this string and exit\n"+\
		"  --input or -i: specify an existing CSV file to merge output with\n"+\
		"  --output or -o: specify a new file to write data to\n"+\
		"  --transcript or -t: check transcript files for updated information\n"+\
		"    NOTE: This is not implemented yet.\n\n"+\
		"Filter String formatting:\n"+\
		"  Filter must follow the format 'category1:item1,item2,... category2:item1,item2,... ...'\n"+\
		"  - Categories and items must be separated by ':'\n"+\
		"  - Categories may be separated by either a ' ' or ';'\n"+\
		"  - Categories correspond directly to tier names in the ELAN files\n"+\
		"  - Items must be separated by a ','\n"+\
		"  - Items may either be a keyword, or an index (number), and may be mixed\n"+\
		"  Usage examples:\n"+\
		"  - to search for words gave, the, and guage and regions verb and object, use filter:\n"+\
		"    'word:gave,the,guage region:verb,object'\n"+\
		"  - to search for the first and third words and phonemes, use filter:\n"+\
		"    'word:1,3 phoneme:1,3'\n"+\
		"OVERALL EXAMPLE: \n"+\
		"  Extract timing for words 1 and 3 in the ELAN files in the current directory and merge with 'in.csv' to output file 'out.csv':\n"+\
		"  - 'python elanfmt.py -i in.csv -o out.csv . words:1,3\n"+\
		"-----------------\n"
	
	path = "."
	fout = None
	fin = None
	trans = False
	
	# do UI stuff
	ignore = False
	for i, arg in enumerate(sys.argv):
		if ignore:
			ignore = False
			continue
		elif arg == "" or i==0: 
			pass;
		elif arg == "--help": 
			print helpstring; 
			sys.exit();
		elif arg == "--output" or arg =="-o":
			if (i+1) < len(sys.argv): 
				if not os.path.isdir(sys.argv[i+1]):
					fout = sys.argv[i+1];
					ignore = True
					continue
				else:
					print "ERROR: cannot use the directory '",sys.argv[i+1],"' as the output file."
			else:
				print "ERROR: please specify an output file for option -o (--output)"
			sys.exit()    
		elif arg == "--transcript":
			trans = True
		elif arg == "--input" or arg =="-i":
			if (i+1) < len(sys.argv): 
				if os.path.isfile(sys.argv[i+1]):
					fin = sys.argv[i+1];
					if not fin.endswith(".csv"): print "WARNING: use of non-CSV files discouraged"
					ignore = True
					continue
				else:
					print "ERROR: input argument '",sys.argv[i+1],"' is not a file"
			else:
				print "ERROR: please specify an input file for option -o (--output)"
			sys.exit()    
		elif arg.startswith("-"):
			for c in arg:
				if c=='-': pass;
				elif c=='t': trans = True;
				elif c=="v": VERBOSE = True;
				elif c=='o' or c=='i': print "Ignoring option %s. It cannot be combined with other args, as it expects an input." % c
				else: print "Unrecognized command %s: invoke command option '-help' for a list of valid commands" % c
		else:
			path = arg
			if not os.path.isdir(path): 
				print "ERROR: ", path, " is not a valid directory."
				sys.exit(1)

			#print filterGen(sys.argv[i+1:])
			print "infile:'{0}' outfile:'{1}'".format(fin, fout)
			elanfmt(path, sys.argv[i+1:], fin, fout, trans)
			break

#determine if running as a script (as opposed to a module)	
if __name__ == "__main__":
	main()